{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas openai langchain streamlit python-dotenv PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv() #take environment variables from .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=KEY, model_name=\"gpt-3.5-turbo\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnumber=5 \\nsubject=\"data science\"\\ntone=\"simple\"\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "number=5 \n",
    "subject=\"data science\"\n",
    "tone=\"simple\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = '''\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, your job is to create a quiz of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conformed to the text.\n",
    "Make sure to format your response like RESPONSE_JSON below and use it as a guide. Ensure to make {number} MCQs.\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generator_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template = TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generator_prompt, output_key=\"quiz\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(input_variables=[\"subject\", \"quiz\"], template=TEMPLATE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain = SequentialChain(chains=[quiz_chain, review_chain], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"], output_variables=[\"quiz\", \"review\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = \"../data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_file_path, \"r\") as file:\n",
    "    TEXT = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI model architectures and how they have evolved\n",
      "Truly generative AI models—deep learning models that can autonomously create content on demand—have evolved over the last dozen years or so. The milestone model architectures during that period include\n",
      "\n",
      "Variational autoencoders (VAEs), which drove breakthroughs in image recognition, natural language processing and anomaly detection.\n",
      " \n",
      "\n",
      "Generative adversarial networks (GANs) and diffusion models, which improved the accuracy of previous applications and enabled some of the first AI solutions for photo-realistic image generation.\n",
      " \n",
      "\n",
      "Transformers, the deep learning model architecture behind the foremost foundation models and generative AI solutions today.\n",
      "\n",
      "Variational autoencoders (VAEs)\n",
      "An autoencoder is a deep learning model comprising two connected neural networks: One that encodes (or compresses) a huge amount of unstructured, unlabeled training data into parameters, and another that decodes those parameters to reconstruct the content. Technically, autoencoders can generate new content, but they’re more useful for compressing data for storage or transfer, and decompressing it for use, than they are for high-quality content generation.\n",
      "\n",
      "Introduced in 2013, variational autoencoders (VAEs) can encode data like an autoencoder, but decode multiple new variations of the content. By training a VAE to generate variations toward a particular goal, it can ‘zero in’ on more accurate, higher-fidelity content over time. Early VAE applications included anomaly detection (e.g., medical image analysis) and natural language generation.\n",
      "\n",
      "Generative adversarial networks (GANs)\n",
      "GANs, introduced in 2014, also comprise two neural networks: A generator, which generates new content, and a discriminator, which evaluates the accuracy and quality the generated data. These adversarial algorithms encourages the model to generate increasingly high-quality outpits.\n",
      "\n",
      "GANs are commonly used for image and video generation, but can generate high-quality, realistic content across various domains. They've proven particularly successful at tasks as style transfer (altering the style of an image from, say, a photo to a pencil sketch) and data augmentation (creating new, synthetic data to increase the size and diversity of a training data set).\n",
      "\n",
      "Diffusion models\n",
      "Also introduced in 2014, diffusion models work by first adding noise to the training data until it’s random and unrecognizable, and then training the algorithm to iteratively diffuse the noise to reveal a desired output.\n",
      "\n",
      "Diffusion models take more time to train than VAEs or GANs, but ultimately offer finer-grained control over output, particularly for high-quality image generation tool. DALL-E, Open AI’s image-generation tool, is driven by a diffusion model.\n",
      "\n",
      "Transformers\n",
      "First documented in a 2017 paper published by Ashish Vaswani and others, transformers evolve the encoder-decoder paradigm to enable a big step forward in the way foundation models are trained, and in the quality and range of content they can produce. These models are at the core of most of today’s headline-making generative AI tools, including ChatGPT and GPT-4, Copilot, BERT, Bard, and Midjourney to name a few.\n",
      "\n",
      "Transformers use a concept called attention—determining and focusing on what’s most important about data within a sequence—to\n",
      "\n",
      "process entire sequences of data—e.g., sentences instead of individual words—simultaneously;\n",
      " \n",
      "\n",
      "capture the context of the data within the sequence;\n",
      " \n",
      "\n",
      "encode the training data into embeddings (also called hyperparameters) that represent the data and its context.\n",
      "\n",
      "In addition to enabling faster training, transformers excel at natural language processing (NLP) and natural language understanding (NLU), and can generate longer sequences of data—e.g., not just answers to questions, but poems, articles or papers—with greater accuracy and higher quality than other deep generative AI models. Transformer models can also be trained or tuned to use tools—e.g., a spreadsheet application, HTML, a drawing program—to output content in a particular format.\n"
     ]
    }
   ],
   "source": [
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serilize the python dictionnary into a json-formatted string\n",
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER=5 \n",
    "SUBJECT=\"Generative AI model architectures and how they have evolved\"\n",
    "TONE=\"simple\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to setup [Token Usage Tracking](https://python.langchain.com/docs/modules/model_io/llms/token_usage_tracking) in LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:Generative AI model architectures and how they have evolved\n",
      "Truly generative AI models—deep learning models that can autonomously create content on demand—have evolved over the last dozen years or so. The milestone model architectures during that period include\n",
      "\n",
      "Variational autoencoders (VAEs), which drove breakthroughs in image recognition, natural language processing and anomaly detection.\n",
      " \n",
      "\n",
      "Generative adversarial networks (GANs) and diffusion models, which improved the accuracy of previous applications and enabled some of the first AI solutions for photo-realistic image generation.\n",
      " \n",
      "\n",
      "Transformers, the deep learning model architecture behind the foremost foundation models and generative AI solutions today.\n",
      "\n",
      "Variational autoencoders (VAEs)\n",
      "An autoencoder is a deep learning model comprising two connected neural networks: One that encodes (or compresses) a huge amount of unstructured, unlabeled training data into parameters, and another that decodes those parameters to reconstruct the content. Technically, autoencoders can generate new content, but they’re more useful for compressing data for storage or transfer, and decompressing it for use, than they are for high-quality content generation.\n",
      "\n",
      "Introduced in 2013, variational autoencoders (VAEs) can encode data like an autoencoder, but decode multiple new variations of the content. By training a VAE to generate variations toward a particular goal, it can ‘zero in’ on more accurate, higher-fidelity content over time. Early VAE applications included anomaly detection (e.g., medical image analysis) and natural language generation.\n",
      "\n",
      "Generative adversarial networks (GANs)\n",
      "GANs, introduced in 2014, also comprise two neural networks: A generator, which generates new content, and a discriminator, which evaluates the accuracy and quality the generated data. These adversarial algorithms encourages the model to generate increasingly high-quality outpits.\n",
      "\n",
      "GANs are commonly used for image and video generation, but can generate high-quality, realistic content across various domains. They've proven particularly successful at tasks as style transfer (altering the style of an image from, say, a photo to a pencil sketch) and data augmentation (creating new, synthetic data to increase the size and diversity of a training data set).\n",
      "\n",
      "Diffusion models\n",
      "Also introduced in 2014, diffusion models work by first adding noise to the training data until it’s random and unrecognizable, and then training the algorithm to iteratively diffuse the noise to reveal a desired output.\n",
      "\n",
      "Diffusion models take more time to train than VAEs or GANs, but ultimately offer finer-grained control over output, particularly for high-quality image generation tool. DALL-E, Open AI’s image-generation tool, is driven by a diffusion model.\n",
      "\n",
      "Transformers\n",
      "First documented in a 2017 paper published by Ashish Vaswani and others, transformers evolve the encoder-decoder paradigm to enable a big step forward in the way foundation models are trained, and in the quality and range of content they can produce. These models are at the core of most of today’s headline-making generative AI tools, including ChatGPT and GPT-4, Copilot, BERT, Bard, and Midjourney to name a few.\n",
      "\n",
      "Transformers use a concept called attention—determining and focusing on what’s most important about data within a sequence—to\n",
      "\n",
      "process entire sequences of data—e.g., sentences instead of individual words—simultaneously;\n",
      " \n",
      "\n",
      "capture the context of the data within the sequence;\n",
      " \n",
      "\n",
      "encode the training data into embeddings (also called hyperparameters) that represent the data and its context.\n",
      "\n",
      "In addition to enabling faster training, transformers excel at natural language processing (NLP) and natural language understanding (NLU), and can generate longer sequences of data—e.g., not just answers to questions, but poems, articles or papers—with greater accuracy and higher quality than other deep generative AI models. Transformer models can also be trained or tuned to use tools—e.g., a spreadsheet application, HTML, a drawing program—to output content in a particular format.\n",
      "You are an expert MCQ maker. Given the above text, your job is to create a quiz of 5 multiple choice questions for Generative AI model architectures and how they have evolved students in simple tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conformed to the text.\n",
      "Make sure to format your response like RESPONSE_JSON below and use it as a guide. Ensure to make 5 MCQs.\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for Generative AI model architectures and how they have evolved students.You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
      "if the quiz is not at per with the cognitive and analytical abilities of the students,update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
      "Quiz_MCQs:\n",
      "{\n",
      "    \"1\": {\n",
      "        \"mcq\": \"Which generative AI model architecture was introduced in 2013 and can encode data like an autoencoder but decode multiple new variations of the content?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Generative adversarial networks (GANs)\",\n",
      "            \"b\": \"Transformers\",\n",
      "            \"c\": \"Variational autoencoders (VAEs)\",\n",
      "            \"d\": \"Diffusion models\"\n",
      "        },\n",
      "        \"correct\": \"c\"\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"mcq\": \"Which generative AI model architecture works by first adding noise to the training data until it's random and unrecognizable, and then training the algorithm to iteratively diffuse the noise to reveal a desired output?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Generative adversarial networks (GANs)\",\n",
      "            \"b\": \"Transformers\",\n",
      "            \"c\": \"Variational autoencoders (VAEs)\",\n",
      "            \"d\": \"Diffusion models\"\n",
      "        },\n",
      "        \"correct\": \"d\"\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"mcq\": \"Which generative AI model architecture was first documented in a 2017 paper published by Ashish Vaswani and others, and is at the core of most of today's headline-making generative AI tools?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Generative adversarial networks (GANs)\",\n",
      "            \"b\": \"Transformers\",\n",
      "            \"c\": \"Variational autoencoders (VAEs)\",\n",
      "            \"d\": \"Diffusion models\"\n",
      "        },\n",
      "        \"correct\": \"b\"\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"mcq\": \"Which generative AI model architecture excels at natural language processing (NLP) and natural language understanding (NLU), and can generate longer sequences of data with greater accuracy and higher quality than other deep generative AI models?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Generative adversarial networks (GANs)\",\n",
      "            \"b\": \"Transformers\",\n",
      "            \"c\": \"Variational autoencoders (VAEs)\",\n",
      "            \"d\": \"Diffusion models\"\n",
      "        },\n",
      "        \"correct\": \"b\"\n",
      "    },\n",
      "    \"5\": {\n",
      "        \"mcq\": \"Which generative AI model architecture is driven by a diffusion model and is used as an image-generation tool by Open AI?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Generative adversarial networks (GANs)\",\n",
      "            \"b\": \"Transformers\",\n",
      "            \"c\": \"Variational autoencoders (VAEs)\",\n",
      "            \"d\": \"Diffusion models\"\n",
      "        },\n",
      "        \"correct\": \"d\"\n",
      "    }\n",
      "}\n",
      "\n",
      "Check from an expert English Writer of the above quiz:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    response=generate_evaluate_chain(\n",
    "        {\n",
    "            \"text\": TEXT,\n",
    "            \"number\": NUMBER,\n",
    "            \"subject\": SUBJECT,\n",
    "            \"tone\": TONE,\n",
    "            \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:2333\n",
      "Prompt Tokens:1734\n",
      "Completion Tokens:599\n",
      "Total Cost:0.0037990000000000003\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Tokens:{cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens:{cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens:{cb.completion_tokens}\")\n",
    "print(f\"Total Cost:{cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Generative AI model architectures and how they have evolved\\nTruly generative AI models—deep learning models that can autonomously create content on demand—have evolved over the last dozen years or so. The milestone model architectures during that period include\\n\\nVariational autoencoders (VAEs), which drove breakthroughs in image recognition, natural language processing and anomaly detection.\\n \\n\\nGenerative adversarial networks (GANs) and diffusion models, which improved the accuracy of previous applications and enabled some of the first AI solutions for photo-realistic image generation.\\n \\n\\nTransformers, the deep learning model architecture behind the foremost foundation models and generative AI solutions today.\\n\\nVariational autoencoders (VAEs)\\nAn autoencoder is a deep learning model comprising two connected neural networks: One that encodes (or compresses) a huge amount of unstructured, unlabeled training data into parameters, and another that decodes those parameters to reconstruct the content. Technically, autoencoders can generate new content, but they’re more useful for compressing data for storage or transfer, and decompressing it for use, than they are for high-quality content generation.\\n\\nIntroduced in 2013, variational autoencoders (VAEs) can encode data like an autoencoder, but decode multiple new variations of the content. By training a VAE to generate variations toward a particular goal, it can ‘zero in’ on more accurate, higher-fidelity content over time. Early VAE applications included anomaly detection (e.g., medical image analysis) and natural language generation.\\n\\nGenerative adversarial networks (GANs)\\nGANs, introduced in 2014, also comprise two neural networks: A generator, which generates new content, and a discriminator, which evaluates the accuracy and quality the generated data. These adversarial algorithms encourages the model to generate increasingly high-quality outpits.\\n\\nGANs are commonly used for image and video generation, but can generate high-quality, realistic content across various domains. They've proven particularly successful at tasks as style transfer (altering the style of an image from, say, a photo to a pencil sketch) and data augmentation (creating new, synthetic data to increase the size and diversity of a training data set).\\n\\nDiffusion models\\nAlso introduced in 2014, diffusion models work by first adding noise to the training data until it’s random and unrecognizable, and then training the algorithm to iteratively diffuse the noise to reveal a desired output.\\n\\nDiffusion models take more time to train than VAEs or GANs, but ultimately offer finer-grained control over output, particularly for high-quality image generation tool. DALL-E, Open AI’s image-generation tool, is driven by a diffusion model.\\n\\nTransformers\\nFirst documented in a 2017 paper published by Ashish Vaswani and others, transformers evolve the encoder-decoder paradigm to enable a big step forward in the way foundation models are trained, and in the quality and range of content they can produce. These models are at the core of most of today’s headline-making generative AI tools, including ChatGPT and GPT-4, Copilot, BERT, Bard, and Midjourney to name a few.\\n\\nTransformers use a concept called attention—determining and focusing on what’s most important about data within a sequence—to\\n\\nprocess entire sequences of data—e.g., sentences instead of individual words—simultaneously;\\n \\n\\ncapture the context of the data within the sequence;\\n \\n\\nencode the training data into embeddings (also called hyperparameters) that represent the data and its context.\\n\\nIn addition to enabling faster training, transformers excel at natural language processing (NLP) and natural language understanding (NLU), and can generate longer sequences of data—e.g., not just answers to questions, but poems, articles or papers—with greater accuracy and higher quality than other deep generative AI models. Transformer models can also be trained or tuned to use tools—e.g., a spreadsheet application, HTML, a drawing program—to output content in a particular format.\",\n",
       " 'number': 5,\n",
       " 'subject': 'Generative AI model architectures and how they have evolved',\n",
       " 'tone': 'simple',\n",
       " 'response_json': '{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}',\n",
       " 'quiz': '{\\n    \"1\": {\\n        \"mcq\": \"Which generative AI model architecture was introduced in 2013 and can encode data like an autoencoder but decode multiple new variations of the content?\",\\n        \"options\": {\\n            \"a\": \"Generative adversarial networks (GANs)\",\\n            \"b\": \"Transformers\",\\n            \"c\": \"Variational autoencoders (VAEs)\",\\n            \"d\": \"Diffusion models\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"2\": {\\n        \"mcq\": \"Which generative AI model architecture works by first adding noise to the training data until it\\'s random and unrecognizable, and then training the algorithm to iteratively diffuse the noise to reveal a desired output?\",\\n        \"options\": {\\n            \"a\": \"Generative adversarial networks (GANs)\",\\n            \"b\": \"Transformers\",\\n            \"c\": \"Variational autoencoders (VAEs)\",\\n            \"d\": \"Diffusion models\"\\n        },\\n        \"correct\": \"d\"\\n    },\\n    \"3\": {\\n        \"mcq\": \"Which generative AI model architecture was first documented in a 2017 paper published by Ashish Vaswani and others, and is at the core of most of today\\'s headline-making generative AI tools?\",\\n        \"options\": {\\n            \"a\": \"Generative adversarial networks (GANs)\",\\n            \"b\": \"Transformers\",\\n            \"c\": \"Variational autoencoders (VAEs)\",\\n            \"d\": \"Diffusion models\"\\n        },\\n        \"correct\": \"b\"\\n    },\\n    \"4\": {\\n        \"mcq\": \"Which generative AI model architecture excels at natural language processing (NLP) and natural language understanding (NLU), and can generate longer sequences of data with greater accuracy and higher quality than other deep generative AI models?\",\\n        \"options\": {\\n            \"a\": \"Generative adversarial networks (GANs)\",\\n            \"b\": \"Transformers\",\\n            \"c\": \"Variational autoencoders (VAEs)\",\\n            \"d\": \"Diffusion models\"\\n        },\\n        \"correct\": \"b\"\\n    },\\n    \"5\": {\\n        \"mcq\": \"Which generative AI model architecture is driven by a diffusion model and is used as an image-generation tool by Open AI?\",\\n        \"options\": {\\n            \"a\": \"Generative adversarial networks (GANs)\",\\n            \"b\": \"Transformers\",\\n            \"c\": \"Variational autoencoders (VAEs)\",\\n            \"d\": \"Diffusion models\"\\n        },\\n        \"correct\": \"d\"\\n    }\\n}',\n",
       " 'review': 'The complexity of the quiz questions is high as it requires knowledge of specific generative AI model architectures and their characteristics. Some questions may be challenging for students not familiar with the topic. To make it more student-friendly, simplify the language and provide hints or explanations for each answer choice.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_str = response.get(\"quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_dict = json.loads(quiz_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'mcq': 'Which generative AI model architecture was introduced in 2013 and can encode data like an autoencoder but decode multiple new variations of the content?',\n",
       "  'options': {'a': 'Generative adversarial networks (GANs)',\n",
       "   'b': 'Transformers',\n",
       "   'c': 'Variational autoencoders (VAEs)',\n",
       "   'd': 'Diffusion models'},\n",
       "  'correct': 'c'},\n",
       " '2': {'mcq': \"Which generative AI model architecture works by first adding noise to the training data until it's random and unrecognizable, and then training the algorithm to iteratively diffuse the noise to reveal a desired output?\",\n",
       "  'options': {'a': 'Generative adversarial networks (GANs)',\n",
       "   'b': 'Transformers',\n",
       "   'c': 'Variational autoencoders (VAEs)',\n",
       "   'd': 'Diffusion models'},\n",
       "  'correct': 'd'},\n",
       " '3': {'mcq': \"Which generative AI model architecture was first documented in a 2017 paper published by Ashish Vaswani and others, and is at the core of most of today's headline-making generative AI tools?\",\n",
       "  'options': {'a': 'Generative adversarial networks (GANs)',\n",
       "   'b': 'Transformers',\n",
       "   'c': 'Variational autoencoders (VAEs)',\n",
       "   'd': 'Diffusion models'},\n",
       "  'correct': 'b'},\n",
       " '4': {'mcq': 'Which generative AI model architecture excels at natural language processing (NLP) and natural language understanding (NLU), and can generate longer sequences of data with greater accuracy and higher quality than other deep generative AI models?',\n",
       "  'options': {'a': 'Generative adversarial networks (GANs)',\n",
       "   'b': 'Transformers',\n",
       "   'c': 'Variational autoencoders (VAEs)',\n",
       "   'd': 'Diffusion models'},\n",
       "  'correct': 'b'},\n",
       " '5': {'mcq': 'Which generative AI model architecture is driven by a diffusion model and is used as an image-generation tool by Open AI?',\n",
       "  'options': {'a': 'Generative adversarial networks (GANs)',\n",
       "   'b': 'Transformers',\n",
       "   'c': 'Variational autoencoders (VAEs)',\n",
       "   'd': 'Diffusion models'},\n",
       "  'correct': 'd'}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz_dict.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "            ]\n",
    "        )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MCQ': 'Which generative AI model architecture was introduced in 2013 and can encode data like an autoencoder but decode multiple new variations of the content?',\n",
       "  'Choices': 'a: Generative adversarial networks (GANs) | b: Transformers | c: Variational autoencoders (VAEs) | d: Diffusion models',\n",
       "  'Correct': 'c'},\n",
       " {'MCQ': \"Which generative AI model architecture works by first adding noise to the training data until it's random and unrecognizable, and then training the algorithm to iteratively diffuse the noise to reveal a desired output?\",\n",
       "  'Choices': 'a: Generative adversarial networks (GANs) | b: Transformers | c: Variational autoencoders (VAEs) | d: Diffusion models',\n",
       "  'Correct': 'd'},\n",
       " {'MCQ': \"Which generative AI model architecture was first documented in a 2017 paper published by Ashish Vaswani and others, and is at the core of most of today's headline-making generative AI tools?\",\n",
       "  'Choices': 'a: Generative adversarial networks (GANs) | b: Transformers | c: Variational autoencoders (VAEs) | d: Diffusion models',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'Which generative AI model architecture excels at natural language processing (NLP) and natural language understanding (NLU), and can generate longer sequences of data with greater accuracy and higher quality than other deep generative AI models?',\n",
       "  'Choices': 'a: Generative adversarial networks (GANs) | b: Transformers | c: Variational autoencoders (VAEs) | d: Diffusion models',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'Which generative AI model architecture is driven by a diffusion model and is used as an image-generation tool by Open AI?',\n",
       "  'Choices': 'a: Generative adversarial networks (GANs) | b: Transformers | c: Variational autoencoders (VAEs) | d: Diffusion models',\n",
       "  'Correct': 'd'}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCQ</th>\n",
       "      <th>Choices</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which generative AI model architecture was int...</td>\n",
       "      <td>a: Generative adversarial networks (GANs) | b:...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which generative AI model architecture works b...</td>\n",
       "      <td>a: Generative adversarial networks (GANs) | b:...</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which generative AI model architecture was fir...</td>\n",
       "      <td>a: Generative adversarial networks (GANs) | b:...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which generative AI model architecture excels ...</td>\n",
       "      <td>a: Generative adversarial networks (GANs) | b:...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which generative AI model architecture is driv...</td>\n",
       "      <td>a: Generative adversarial networks (GANs) | b:...</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 MCQ  \\\n",
       "0  Which generative AI model architecture was int...   \n",
       "1  Which generative AI model architecture works b...   \n",
       "2  Which generative AI model architecture was fir...   \n",
       "3  Which generative AI model architecture excels ...   \n",
       "4  Which generative AI model architecture is driv...   \n",
       "\n",
       "                                             Choices Correct  \n",
       "0  a: Generative adversarial networks (GANs) | b:...       c  \n",
       "1  a: Generative adversarial networks (GANs) | b:...       d  \n",
       "2  a: Generative adversarial networks (GANs) | b:...       b  \n",
       "3  a: Generative adversarial networks (GANs) | b:...       b  \n",
       "4  a: Generative adversarial networks (GANs) | b:...       d  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Generative_AI_Quiz.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11-06-2024_17:02:40'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetime.now().strftime('%d-%m-%Y_%H:%M:%S')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
